{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import scipy as sc\n",
    "import math as ma\n",
    "from scipy import linalg, optimize, constants, interpolate, special, stats\n",
    "from math import exp, pow, sqrt, log\n",
    "\n",
    "import seaborn as sns #spezielle Graphikdarstellungen\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "#den oberen Teil kennt man schon vom letzten Mal...\n",
    "#Theano kommt neu dazu - \n",
    "#Library für effiziente Berechnungen mit großen Matrizen -> DeepLearning!\n",
    "import theano \n",
    "\n",
    " \n",
    "#Jetzt noch scikit-learn:\n",
    "#hier stecken viele Funktionalitäten drin, die man gut brauchen kann: \n",
    "#Fehlerfunktionen, Standard-Modelltypen, Preprocessing-Algorithmen, Daten... \n",
    "\n",
    "import sklearn as sl \n",
    "from sklearn import model_selection, metrics, datasets\n",
    "from sklearn.preprocessing import OneHotEncoder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Das \"selbstgemachte\" MLP vom letzten Mal soll jetzt an den MNIST Daten getestet werden.\n",
    "Dazu kopiert man sich am besten aus dem letzten Notebook die vollständige Version der MLP-Definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class definition für Neural Network object\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #Initialisierung\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "    \n",
    "        #setze Nummer der nodes in jeder input, hidden & output layer\n",
    "        self.inodes = inputnodes #self sorgt dafür, daß die Funktion beim Erzeugen dem richtigen Objekt zugewiesen wird\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        #Gewichtmatrizen input->hidden wih und hidden->output who\n",
    "        #die Gewichte innerhalb der arrays sind w_i_j, \n",
    "        #womit das Neuron i mit dem j-ten der nächsten Schicht verbunden wird\n",
    "        \n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes,-0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes,-0.5), (self.onodes, self.hnodes))\n",
    "                \n",
    "        #learning rate\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "    \n",
    "        #Aktivierungsfunktion der Hidden Schicht z.B. Sigmoid (logistic activation) Funktion\n",
    "        #gebräuchlich wäre auch tanh oder ReLU\n",
    "        \n",
    "        self.activation_function = lambda x:  special.expit(x) #lambda sorgt dafür, daß die Fkt. anonym bleibt\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    #Training\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #Inputs und Targets als 2D NumPy array schreiben\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #Eingangssignale in die Hidden Schicht\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        #Ausgangssignale aus der Hiddenschicht\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #Eingangssignale in Ausgabeschicht\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        #Berechnung der Ausgangssignale der Output-Schicht \n",
    "        #d.h. Anwendung der Aktivierungsfunktion\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        #Berechnung des Fehlers Output-Target oder Target-Output - keine spezifische Fehlerfunktion\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        #Berechnung der lokalen Fehler im Backpropagation Fehlerfluß: errors_hid = weights.T_hid_out*errors_out\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        #Update der Gewichte von Hidden nach Output auf Basis der berechneten Fehler\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs)) \n",
    "        # += heißt einfach nur zähle zur Variable die neue Menge dazu: x +=3 -> x = x+3\n",
    "        \n",
    "        #Update der Gewichte von Input nach Hidden auf Basis der berechneten Fehler\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs)) \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    #Query\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        #sicherstellen, daß die Liste der Inputs ein 2D NumPy array ist\n",
    "        #für die anschl. Rechnungen muß das array noch transponiert werden\n",
    "        inputs = np.array(inputs_list, ndmin=2).T \n",
    "        \n",
    "        #Berechnung der Eingangssignale in die Hiddenschicht \n",
    "        #d.h. Multiplikation der ersten Matrix mit dem Input-array\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        \n",
    "        #Berechnung der Ausgangssignale der Hiddenschicht \n",
    "        #d.h. Anwendung der Aktivierungsfunktion\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #Berechnung der Eingangssignale in die Output-Schicht\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        #Berechnung der Ausgangssignale der Output-Schicht \n",
    "        #d.h. Anwendung der Aktivierungsfunktion\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs       \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Jetzt braucht man den Trainings- und den Testdatensatz\n",
    "Am besten macht man zuerst das Preprocessing und speichert die Ergebnisse lokal für später."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testdaten einlesen\n",
    "\n",
    "data_file_test = open('./mnist_test.csv', 'r')\n",
    "data_list_test = data_file_test.readlines() \n",
    "data_file_test.close()\n",
    "\n",
    "#Trainingsdaten einlesen\n",
    "data_file_train = open('./mnist_train.csv', 'r') \n",
    "data_list_train = data_file_train.readlines()\n",
    "data_file_train.close()\n",
    "\n",
    "#Check der Dimensionen \n",
    "print(len(data_list_test)) #10000 Testdatensätze \n",
    "print(len(data_list_train)) #60000 Trainingsdatensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alle Trainingsbeispiele durchgehen - erst leere Liste erzeugen\n",
    "inputs_train = np.empty([60000,784])\n",
    "targets_train = np.empty([60000,10])\n",
    " \n",
    "\n",
    "k = 0\n",
    "for record in data_list_train:    \n",
    "    #an Kommas auftrennen\n",
    "    all_values_train = record.split(',')\n",
    "    \n",
    "    #Skalieren und shiften\n",
    "    inputs_t = (np.asfarray(all_values_train[1:]) / 255.0 * 0.999) + 0.0001\n",
    "    \n",
    "    #Target generieren\n",
    "    numberoutputs = 10\n",
    "    targets_t = np.zeros(numberoutputs) + 0.0001\n",
    "    targets_t[int(all_values_train[0])] = 0.999\n",
    "  \n",
    "    inputs_train[k]  = inputs_t\n",
    "    targets_train[k] = targets_t\n",
    "    \n",
    "    k += 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Alle Testbeispiele durchgehen - erst leere Liste erzeugen\n",
    "inputs_test = np.empty([10000,784])\n",
    "targets_test = np.empty([10000,10])\n",
    "\n",
    "k = 0\n",
    "for record in data_list_test:    \n",
    "    #an Kommas auftrennen\n",
    "    all_values_test = record.split(',')\n",
    "    #Skalieren und shiften\n",
    "    inputs_te = (np.asfarray(all_values_test[1:]) / 255.0 * 0.999) + 0.0001\n",
    "    #Target generieren\n",
    "    numberoutputs_test = 10\n",
    "    targets_te = np.zeros(numberoutputs_test) + 0.0001\n",
    "    targets_te[int(all_values_test[0])] = 0.999\n",
    "  \n",
    "    inputs_test[k]  = inputs_te\n",
    "    targets_test[k] = targets_te\n",
    "    \n",
    "    k += 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Damit ist die Vorverarbeitung der Daten erstmal abgeschlossen.\n",
    "Für später sichert man das Ergebnis am besten in einem lokalen Ordner. Von dort kann man es dann später jederzeit wieder laden...\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#jetzt Daten im Python Format sichern \n",
    "#laden ist später jederzeit mit dem Befehl \"load\" wieder möglich\n",
    "    \n",
    "from tempfile import TemporaryFile\n",
    "mnist_targets_train = TemporaryFile()\n",
    "mnist_inputs_train = TemporaryFile()\n",
    " \n",
    "mnist_targets_test = TemporaryFile()\n",
    "mnist_inputs_test = TemporaryFile()\n",
    " \n",
    "np.save(mnist_targets_train, targets_train)\n",
    "np.save(mnist_inputs_train, inputs_train)\n",
    "np.save(mnist_targets_test, targets_test)\n",
    "np.save(mnist_inputs_test, inputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Jetzt soll die Performance des MLPs an den konkreten Daten getestet werden. Dazu muß man ertmal ein spezifisches MLP Objekt strukturieren...  \n",
    " \n",
    "Also:  \n",
    " \n",
    "Definition eines speziellen MLPs (Anzahl Inputs, Hidden, Outputs & Lernrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anzahl der Inputs, Hidden und Output Neuronen\n",
    "input_nodes = 784 #Bild 28x28 Pixel\n",
    "hidden_nodes = 100 #Metaparameter - setzen wir jetzt einfach mal so auf 100\n",
    "output_nodes = 10 #10 Klassen = 10 verschiedene Zahlen\n",
    " \n",
    "#Lernrate = Metaparameter - muß man testen was hier gut ist\n",
    "learning_rate = 0.3\n",
    " \n",
    "#Erzeugen eines konkreten Neuro-Objektes\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jetzt das Neuronale Netz mit allen Trainingsbeispielen nacheinander trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuronales Netz trainieren\n",
    "#Alle Trainingsbeispiele durchgehen\n",
    " \n",
    "for k in range(0,int(len(inputs_train))):\n",
    "    \n",
    "    n.train(inputs_train[k], targets_train[k])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test, ob sinnvolle Ausgaben generiert werden\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.query(inputs_test[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleich von Output und Target für ein Beispiel aus der Testmenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Auswahl des Testbeispiels\n",
    "nr_test_example = 140\n",
    " \n",
    "#graphische Darstellung\n",
    "image_array1 = np.asfarray(inputs_test[nr_test_example]).reshape((28,28)) #28x28 array draus machen\n",
    "plt.imshow(image_array1, cmap='Greys', interpolation = 'None') #plotten\n",
    " \n",
    "#Abfrage des MLP Outputs\n",
    "result = n.query(inputs_test[nr_test_example])\n",
    " \n",
    "#mit dem argmax - Befehl wird die Position ausgegeben an der in einer Liste das Maximum zu finden ist\n",
    "#bei unserer One-Hot-Codierung der Targets/Outputs ist das genau die Zahl, die auf dem Bild dargestellt ist (Max)\n",
    "print ('output')\n",
    "print (np.argmax(result))\n",
    " \n",
    "print ('target') \n",
    "print (np.argmax(targets_test[nr_test_example]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "...damit kann man jetzt einzelne Beipiele anschauen und sehen, ob das MLP richtig klassifiziert.  \n",
    "Zur Bewertung der Gesamtperformanz reicht das nicht.  \n",
    "Am besten berechnet man dafür die Hitrate, also den prozentualen Anteil der richtig klassifizierten Beispiele:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Berechnung der Hit-Rate auf dem gesamten Testdatensatz\n",
    "#zunächst wird eine leere liste angelegt\n",
    "#dann wird für alle Beispiele mit argmax die Ausgabe/Target als Zahl berechnet\n",
    " \n",
    "#wenn richtig klassifiziert wurde muß gelten:\n",
    "#output=target\n",
    "#das heißt \"Treffer\"\n",
    "#in dem Fall wird eine 1 an die score-liste angehängt\n",
    "#falls kein Treffer erzielt wurde hängt man eine Null an\n",
    " \n",
    "score = []\n",
    " \n",
    "for k in range(0,int(len(inputs_test))):\n",
    "    output = np.argmax(n.query(inputs_test[k]))\n",
    "    target = np.argmax(targets_test[k])\n",
    "    if (output == target):\n",
    "        score.append(1)\n",
    "    else:\n",
    "        score.append(0)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#die Hit-Rate berechnet sich als Prozentsatz der Treffer innerhalb der Testmenge\n",
    "#also: Summe der Einträge in der score-Liste/Anzahl der Testbeispiele\n",
    " \n",
    "score_array = np.asfarray(score)\n",
    "print (\"Hit Rate =\", score_array.sum()/score_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Aufgabe 1)\n",
    " \n",
    "- Modifizieren Sie das Netz, indem Sie\n",
    " \n",
    "1) die Anzahl der Hidden Neuronen oder  \n",
    "2) die Lernrate\n",
    " \n",
    "verändern und trainieren Sie jeweils das Netz neu.  \n",
    "\n",
    "- Analysieren Sie das Ergebnis bzgl. der Hit-Rate auf der Testmenge.\n",
    " \n",
    "Hinweis: das Ändern von zwei Parametern zugleich ist ungünstig, weil man eventuelle Verbesserungen/Verschlechterungen dann nicht mehr eindeutig zuordnen kann..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2)\n",
    "\n",
    "Ein Durchlauf mit allen Trainingsbeispielen entspricht einer Lernepoche!\n",
    "\n",
    "- Erweitern Sie die Rechnung von oben so, daß mehrere Epochen gelernt werden kann.  \n",
    "- Speichern Sie die Hit-Rates während des Trainingsverlaufes (mehrere Lernepochen) sowohl für die Trainingsmenge als auch für die Testmenge ab und stellen Sie das Ergebnis in einer geeigneten Graphik dar.  \n",
    "- Veranschaulichen Sie den Effekt, den die Zahl der Neuronen und der Lernrate hat indem Sie die Graphik aus 2) für die verschiedenen Setups vergleichen.\n",
    "- Wie viele Lernepochen sind sinnvoll? Wäre es sinnvoll ein \"Early Stopping\" einzuführen?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3)\n",
    "\n",
    "Bisher wurde mit allen Testdaten trainiert.\n",
    "\n",
    "- Wie wirkt es sich aus, wenn weniger Daten zum Training verfügbar sind?   \n",
    "Verwenden Sie für den Test 80%, 50% und 20% der verfügbaren Trainingsdaten und stellen sie das Ergebnis in einer geeigneten Graphik dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
